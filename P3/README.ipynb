{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation with AutoEncoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 128, 128, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import CelebADataset\n",
    "from models import VAE, GAN\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from utils import plot_history\n",
    "import tensorflow as tf\n",
    "train, val, test = map(CelebADataset, ('train', 'val', 'test'))\n",
    "vae = VAE(CelebADataset.IMG_SIZE, 100, pool='strides', residual=False, skips=True)\n",
    "inputs = tf.random.normal((10, 128, 128, 3))\n",
    "vae.model(inputs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We followed the CelebA dataset [official split](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) to create a train (80%), validation (10%) and test (10%) subsets. In order to create the same split, the script [data.py](data.py) automatically prepares the dataset subfolders to load the images (it is required to previously download the [archive.zip](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset) from Kaggle)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline \n",
    "\n",
    "### Variational AutoEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "vae = VAE(CelebADataset.IMG_SIZE, hidden_size = 200, filters = [16, 32, 32, 32], kernels = [3,3,3,3], strides = [2,2,2,2])\n",
    "vae_history = vae.train(train, val, test, 'results/vae/', optimizer=Adam(1e-4), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(vae_history, 'loss').show()\n",
    "plot_history(vae_history, 'kl_loss').show()\n",
    "plot_history(vae_history, 'r_loss').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = WGAN(CelebADataset.IMG_SIZE, hidden_size = 128, critic_steps=3, gp_weight=10)\n",
    "wgan_history = wgan.train(train, test, './results/wgan/', epochs=10, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(wgan_history, name=['c_acc', 'g_acc']).update_xaxes(title_text='acc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
