{"cells":[{"cell_type":"markdown","id":"22ae1057","metadata":{"id":"22ae1057"},"source":["#  Deep Learning\n","\n","## U6:  GANs  \n","\n","Notebooks that accompany lectures.\n","\n","Taken from the github directory for book by Foster."]},{"cell_type":"markdown","id":"b076bd1a-b236-4fbc-953d-8295b25122ae","metadata":{"id":"b076bd1a-b236-4fbc-953d-8295b25122ae"},"source":["# ü§™ WGAN - CelebA Faces"]},{"cell_type":"markdown","id":"9235cbd1-f136-411c-88d9-f69f270c0b96","metadata":{"id":"9235cbd1-f136-411c-88d9-f69f270c0b96"},"source":["In this notebook, we'll walk through the steps required to train your own Wasserstein GAN on the CelebA faces dataset"]},{"cell_type":"markdown","id":"098731a6-4193-4fda-9018-b14114c54250","metadata":{"id":"098731a6-4193-4fda-9018-b14114c54250"},"source":["The code has been adapted from the excellent [WGAN-GP tutorial](https://keras.io/examples/generative/wgan_gp/) created by Aakash Kumar Nain, available on the Keras website."]},{"cell_type":"code","execution_count":3,"id":"yum0EjpNq7T-","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143755,"status":"ok","timestamp":1716500948007,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"yum0EjpNq7T-","outputId":"3bd8c5c9-1753-4b7e-cb53-a08cb69c62c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["import zipfile\n","from google.colab import drive\n","\n","drive.mount('/content/drive/')\n","\n","zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/MIA/DL/archive.zip\", 'r')\n","zip_ref.extractall(\"/dataset/celeb\")\n","zip_ref.close()"]},{"cell_type":"code","execution_count":4,"id":"84acc7be-6764-4668-b2bb-178f63deeed3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3353,"status":"ok","timestamp":1716500951349,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"84acc7be-6764-4668-b2bb-178f63deeed3","outputId":"ed3498a6-b676-4723-bc7e-1c66bfe7ec21","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1g570Pw-EX7SVf_PL7-lpSQJdwY3y-e1l/DL\n"]}],"source":["%load_ext autoreload\n","%autoreload 2\n","import numpy as np\n","import glob, os\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, callbacks, utils, metrics, optimizers\n","from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n","\n","%cd /content/drive/MyDrive/MIA/DL/\n","from utils_p3 import display, sample_batch, load_and_preprocess_data, scale_images, calculate_fid"]},{"cell_type":"markdown","id":"339e6268-ebd7-4feb-86db-1fe7abccdbe5","metadata":{"id":"339e6268-ebd7-4feb-86db-1fe7abccdbe5"},"source":["## 0. Parameters <a name=\"parameters\"></a>"]},{"cell_type":"code","execution_count":5,"id":"1b2ee6ce-129f-4833-b0c5-fa567381c4e0","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1716500951350,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"1b2ee6ce-129f-4833-b0c5-fa567381c4e0"},"outputs":[],"source":["IMAGE_SIZE = 32\n","CHANNELS = 3\n","\n","BATCH_SIZE = 64\n","NUM_FEATURES = 128\n","Z_DIM = 128\n","\n","N_BLOCKS = 10\n","EPOCHS = 10\n","STEPS_PER_EPOCH=1500\n","\n","\n","LEARNING_RATE = 0.0002\n","CRITIC_STEPS = 3\n","\n","ADAM_BETA_1 = 0.5\n","ADAM_BETA_2 = 0.999\n","\n","GP_WEIGHT = 10.0\n","LOAD_MODEL = False\n","ADAM_BETA_1 = 0.5\n","ADAM_BETA_2 = 0.9"]},{"cell_type":"markdown","id":"b7716fac-0010-49b0-b98e-53be2259edde","metadata":{"id":"b7716fac-0010-49b0-b98e-53be2259edde"},"source":["## 1. Prepare the data <a name=\"prepare\"></a>"]},{"cell_type":"code","execution_count":6,"id":"9a73e5a4-1638-411c-8d3c-29f823424458","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11052,"status":"ok","timestamp":1716500962392,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"9a73e5a4-1638-411c-8d3c-29f823424458","outputId":"294cb52c-80a9-4442-aca8-d2b69378b704","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 202599 files belonging to 1 classes.\n","Using 202535 files for training.\n","Using 64 files for validation.\n"]}],"source":["images_folder = \"/dataset/celeb/img_align_celeba\"\n","\n","# Save the number of images\n","filenames = np.array(glob.glob(os.path.join(images_folder, '*/*.jpg')))\n","NUM_IMAGES = len(filenames)\n","\n","# Load and preprocess (saving BATCH_SIZE images to the validation set)\n","train_data, val_data = load_and_preprocess_data(images_folder, IMAGE_SIZE, BATCH_SIZE, option=1, val_ratio=BATCH_SIZE/NUM_IMAGES)\n","\n","example_images_train = sample_batch(train_data)\n","example_images_val = sample_batch(val_data)"]},{"cell_type":"markdown","id":"aff50401-3abe-4c10-bba8-b35bc13ad7d5","metadata":{"id":"aff50401-3abe-4c10-bba8-b35bc13ad7d5","tags":[]},"source":["## 2. Build the WGAN-GP <a name=\"build\"></a>"]},{"cell_type":"code","execution_count":7,"id":"371eb69d-e534-4666-a412-b5b6fe24689a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1716500962393,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"371eb69d-e534-4666-a412-b5b6fe24689a","outputId":"b1c9bdf0-3577-4f52-bc3d-ac93f6f01015"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 16, 16, 64)        3136      \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 16, 16, 64)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 8, 8, 128)         131200    \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 128)         0         \n","                                                                 \n"," dropout (Dropout)           (None, 8, 8, 128)         0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 4, 4, 256)         524544    \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 256)         0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 4, 4, 256)         0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 1, 1, 1)           4097      \n","                                                                 \n"," flatten (Flatten)           (None, 1)                 0         \n","                                                                 \n","=================================================================\n","Total params: 662977 (2.53 MB)\n","Trainable params: 662977 (2.53 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["critic_input = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n","x = layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\")(critic_input)\n","x = layers.LeakyReLU(0.2)(x)\n","x = layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\")(x)\n","x = layers.LeakyReLU()(x)\n","x = layers.Dropout(0.3)(x)\n","x = layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\")(x)\n","x = layers.LeakyReLU(0.2)(x)\n","x = layers.Dropout(0.3)(x)\n","x = layers.Conv2D(1, kernel_size=4, strides=1, padding=\"valid\")(x)\n","critic_output = layers.Flatten()(x)\n","\n","critic = models.Model(critic_input, critic_output)\n","critic.summary()"]},{"cell_type":"code","execution_count":8,"id":"086e2584-c60d-4990-89f4-2092c44e023e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":537,"status":"ok","timestamp":1716500962927,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"086e2584-c60d-4990-89f4-2092c44e023e","outputId":"be89e687-bd5c-4a57-dc03-5268d3df578e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 128)]             0         \n","                                                                 \n"," reshape (Reshape)           (None, 1, 1, 128)         0         \n","                                                                 \n"," conv2d_transpose (Conv2DTr  (None, 4, 4, 256)         524288    \n"," anspose)                                                        \n","                                                                 \n"," batch_normalization (Batch  (None, 4, 4, 256)         1024      \n"," Normalization)                                                  \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 256)         0         \n","                                                                 \n"," conv2d_transpose_1 (Conv2D  (None, 8, 8, 128)         524288    \n"," Transpose)                                                      \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 8, 8, 128)         512       \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_4 (LeakyReLU)   (None, 8, 8, 128)         0         \n","                                                                 \n"," conv2d_transpose_2 (Conv2D  (None, 16, 16, 64)        131072    \n"," Transpose)                                                      \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 64)        0         \n","                                                                 \n"," conv2d_transpose_3 (Conv2D  (None, 32, 32, 3)         3075      \n"," Transpose)                                                      \n","                                                                 \n","=================================================================\n","Total params: 1184515 (4.52 MB)\n","Trainable params: 1183619 (4.52 MB)\n","Non-trainable params: 896 (3.50 KB)\n","_________________________________________________________________\n"]}],"source":["generator_input = layers.Input(shape=(Z_DIM,))\n","x = layers.Reshape((1, 1, Z_DIM))(generator_input)\n","x = layers.Conv2DTranspose(256, kernel_size=4, strides=1, padding=\"valid\", use_bias=False)(x)\n","x = layers.BatchNormalization(momentum=0.9)(x)\n","x = layers.LeakyReLU(0.2)(x)\n","x = layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)\n","x = layers.BatchNormalization(momentum=0.9)(x)\n","x = layers.LeakyReLU(0.2)(x)\n","x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)\n","x = layers.BatchNormalization(momentum=0.9)(x)\n","x = layers.LeakyReLU(0.2)(x)\n","generator_output = layers.Conv2DTranspose(CHANNELS, kernel_size=4, strides=2, padding=\"same\", activation=\"tanh\")(x)\n","generator = models.Model(generator_input, generator_output)\n","generator.summary()"]},{"cell_type":"code","execution_count":9,"id":"88010f20-fb61-498c-b2b2-dac96f6c03b3","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1716500962927,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"88010f20-fb61-498c-b2b2-dac96f6c03b3"},"outputs":[],"source":["class WGANGP(models.Model):\n","    def __init__(self, critic, generator, latent_dim, critic_steps, gp_weight):\n","        super(WGANGP, self).__init__()\n","        self.critic = critic\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","        self.critic_steps = critic_steps\n","        self.gp_weight = gp_weight\n","\n","    def compile(self, c_optimizer, g_optimizer):\n","        super(WGANGP, self).compile()\n","        self.c_optimizer = c_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.c_wass_loss_metric = metrics.Mean(name=\"c_wass_loss\")\n","        self.c_gp_metric = metrics.Mean(name=\"c_gp\")\n","        self.c_loss_metric = metrics.Mean(name=\"c_loss\")\n","        self.g_loss_metric = metrics.Mean(name=\"g_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [self.c_loss_metric, self.c_wass_loss_metric, self.c_gp_metric, self.g_loss_metric]\n","\n","    def gradient_penalty(self, batch_size, real_images, fake_images):\n","        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n","        diff = fake_images - real_images\n","        interpolated = real_images + alpha * diff\n","\n","        with tf.GradientTape() as gp_tape:\n","            gp_tape.watch(interpolated)\n","            pred = self.critic(interpolated, training=True)\n","\n","        grads = gp_tape.gradient(pred, [interpolated])[0]\n","        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n","        gp = tf.reduce_mean((norm - 1.0) ** 2)\n","        return gp\n","\n","    def train_step(self, real_images):\n","        batch_size = tf.shape(real_images)[0]\n","\n","        for i in range(self.critic_steps):\n","            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","\n","            with tf.GradientTape() as tape:\n","                fake_images = self.generator(random_latent_vectors, training=True)\n","                fake_predictions = self.critic(fake_images, training=True)\n","                real_predictions = self.critic(real_images, training=True)\n","\n","                c_wass_loss = tf.reduce_mean(fake_predictions) - tf.reduce_mean(real_predictions)\n","                c_gp = self.gradient_penalty(batch_size, real_images, fake_images)\n","                c_loss = c_wass_loss + c_gp * self.gp_weight\n","\n","            c_gradient = tape.gradient(c_loss, self.critic.trainable_variables)\n","            self.c_optimizer.apply_gradients(zip(c_gradient, self.critic.trainable_variables))\n","\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        with tf.GradientTape() as tape:\n","            fake_images = self.generator(random_latent_vectors, training=True)\n","            fake_predictions = self.critic(fake_images, training=True)\n","            g_loss = -tf.reduce_mean(fake_predictions)\n","\n","        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n","        self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_variables))\n","\n","\n","      # Calculate Critic and Generator Accuracy\n","        c_acc = tf.reduce_mean(tf.cast(tf.math.greater(real_predictions, 0), tf.float32)) * 100\n","        g_acc = tf.reduce_mean(tf.cast(tf.math.less(fake_predictions, 0), tf.float32)) * 100\n","\n","        self.c_loss_metric.update_state(c_loss)\n","        self.c_wass_loss_metric.update_state(c_wass_loss)\n","        self.c_gp_metric.update_state(c_gp)\n","        self.g_loss_metric.update_state(g_loss)\n","\n","        #return {m.name: m.result() for m in self.metrics,'c_acc': c_acc,'g_acc': g_acc}\n","        return {**{m.name: m.result() for m in self.metrics}, 'c_acc': c_acc, 'g_acc': g_acc}"]},{"cell_type":"code","execution_count":10,"id":"edf2f892-9209-42ee-b251-1e7604df5335","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1716500962928,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"edf2f892-9209-42ee-b251-1e7604df5335"},"outputs":[],"source":["# Create a GAN\n","wgangp = WGANGP(critic=critic, generator=generator, latent_dim=Z_DIM, critic_steps=CRITIC_STEPS, gp_weight=GP_WEIGHT)"]},{"cell_type":"code","execution_count":11,"id":"b2f48907-fa82-41b5-8caa-813b2f232c79","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1716500962928,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"b2f48907-fa82-41b5-8caa-813b2f232c79","tags":[]},"outputs":[],"source":["if LOAD_MODEL:\n","    wgangp.load_weights(\"./checkpoint/checkpoint.ckpt\")"]},{"cell_type":"markdown","id":"35b14665-4359-447b-be58-3fd58ba69084","metadata":{"id":"35b14665-4359-447b-be58-3fd58ba69084"},"source":["## 3. Train the GAN <a name=\"train\"></a>"]},{"cell_type":"code","execution_count":12,"id":"b429fdad-ea9c-45a2-a556-eb950d793824","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1716500962928,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"b429fdad-ea9c-45a2-a556-eb950d793824"},"outputs":[],"source":["# Compile the GAN\n","wgangp.compile(\n","    c_optimizer=optimizers.Adam(learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2),\n","    g_optimizer=optimizers.Adam(learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2),\n",")"]},{"cell_type":"code","execution_count":13,"id":"c525e44b-b3bb-489c-9d35-fcfe3e714e6a","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716500962928,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"c525e44b-b3bb-489c-9d35-fcfe3e714e6a"},"outputs":[],"source":["# Create a model save checkpoint\n","model_checkpoint_callback = callbacks.ModelCheckpoint(\n","    filepath=\"./checkpoint/checkpoint.ckpt\",\n","    save_weights_only=True,\n","    save_freq=\"epoch\",\n","    verbose=0)\n","\n","tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n","\n","\n","class ImageGenerator(callbacks.Callback):\n","    def __init__(self, num_img, latent_dim):\n","        self.num_img = num_img\n","        self.latent_dim = latent_dim\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n","        generated_images = self.model.generator(random_latent_vectors)\n","        generated_images = generated_images * 127.5 + 127.5\n","        generated_images = generated_images.numpy()\n","        display(generated_images, save_to=\"./output/generated_img_%03d.png\" % (epoch), cmap=None)"]},{"cell_type":"code","execution_count":14,"id":"043ab353","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716500962929,"user":{"displayName":"Sebas Rodr√≠guez","userId":"18005544226969816149"},"user_tz":-120},"id":"043ab353"},"outputs":[],"source":["class LossHistory(callbacks.Callback):\n","    def on_train_begin(self, logs=None):\n","        self.history = {\n","            'c_loss': [],\n","            'g_loss': [],\n","            'c_acc': [],\n","            'g_acc': [],\n","        }\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        self.history['c_loss'].append(logs['c_loss'])\n","        self.history['g_loss'].append(logs['g_loss'])\n","        self.history['c_acc'].append(logs['c_acc'])\n","        self.history['g_acc'].append(logs['g_acc'])\n","\n","loss_history = LossHistory()"]},{"cell_type":"code","execution_count":null,"id":"9164c9f9","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":883},"id":"9164c9f9","outputId":"0a0ccd58-d545-420e-b1b6-ffa0e0b281ad","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 0s 0us/step\n","Epoch 1/10\n","1500/1500 [==============================] - ETA: 0s - c_loss: -1175766.1250 - c_wass_loss: -2331710.0000 - c_gp: 115594.0625 - g_loss: -12904.7812 - c_acc: 100.0000 - g_acc: 0.0000e+00\n","Saved to ./output/generated_img_000.png\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABiEAAACXCAYAAABzwvhEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFKUlEQVR4nO3dMQ4CMQwAwQTx/y+bmiu4K1idQDNdpBTuV5b3zMwCAAAAAAD4ssfdAwAAAAAAAP9JhAAAAAAAABIiBAAAAAAAkBAhAAAAAACAhAgBAAAAAAAkRAgAAAAAACAhQgAAAAAAAAkRAgAAAAAASIgQAAAAAABAQoQAAAAAAAASIgQAAAAAAJAQIQAAAAAAgIQIAQAAAAAAJEQIAAAAAAAgIUIAAAAAAAAJEQIAAAAAAEiIEAAAAAAAQEKEAAAAAAAAEiIEAAAAAACQECEAAAAAAICECAEAAAAAACRECAAAAAAAICFCAAAAAAAACRECAAAAAABIiBAAAAAAAEBChAAAAAAAABIiBAAAAAAAkBAhAAAAAACAhAgBAAAAAAAkRAgAAAAAACAhQgAAAAAAAAkRAgAAAAAASIgQAAAAAABAQoQAAAAAAAASIgQAAAAAAJAQIQAAAAAAgIQIAQAAAAAAJEQIAAAAAAAgIUIAAAAAAAAJEQIAAAAAAEiIEAAAAAAAQEKEAAAAAAAAEiIEAAAAAACQECEAAAAAAICECAEAAAAAACRECAAAAAAAICFCAAAAAAAACRECAAAAAABIiBAAAAAAAEBChAAAAAAAABIiBAAAAAAAkBAhAAAAAACAhAgBAAAAAAAkRAgAAAAAACAhQgAAAAAAAAkRAgAAAAAASIgQAAAAAABAQoQAAAAAAAASIgQAAAAAAJAQIQAAAAAAgIQIAQAAAAAAJEQIAAAAAAAgIUIAAAAAAAAJEQIAAAAAAEiIEAAAAAAAQEKEAAAAAAAAEiIEAAAAAACQECEAAAAAAICECAEAAAAAACRECAAAAAAAICFCAAAAAAAACRECAAAAAABIiBAAAAAAAEBChAAAAAAAABIiBAAAAAAAkBAhAAAAAACAhAgBAAAAAAAkRAgAAAAAACAhQgAAAAAAAAkRAgAAAAAASIgQAAAAAABAQoQAAAAAAAASIgQAAAAAAJAQIQAAAAAAgIQIAQAAAAAAJEQIAAAAAAAgIUIAAAAAAAAJEQIAAAAAAEiIEAAAAAAAQEKEAAAAAAAAEiIEAAAAAACQECEAAAAAAICECAEAAAAAACRECAAAAAAAICFCAAAAAAAACRECAAAAAABIiBAAAAAAAEBChAAAAAAAABIiBAAAAAAAkBAhAAAAAACAhAgBAAAAAAAkRAgAAAAAACAhQgAAAAAAAAkRAgAAAAAASIgQAAAAAABAQoQAAAAAAAASIgQAAAAAAJAQIQAAAAAAgIQIAQAAAAAAJEQIAAAAAAAgIUIAAAAAAAAJEQIAAAAAAEiIEAAAAAAAQEKEAAAAAAAAEiIEAAAAAACQECEAAAAAAICECAEAAAAAACRECAAAAAAAICFCAAAAAAAACRECAAAAAABIiBAAAAAAAEBChAAAAAAAABIiBAAAAAAAkBAhAAAAAACAhAgBAAAAAAAkRAgAAAAAACAhQgAAAAAAAAkRAgAAAAAASIgQAAAAAABAQoQAAAAAAAASIgQAAAAAAJAQIQAAAAAAgIQIAQAAAAAAJEQIAAAAAAAgIUIAAAAAAAAJEQIAAAAAAEg87x4AAAAAAAD4DbPm7b3X/vjfJgQAAAAAAJAQIQAAAAAAgIQIAQAAAAAAJNyEAAAAAAAALjm7AXFkEwIAAAAAAEiIEAAAAAAAQEKEAAAAAAAAEiIEAAAAAACQECEAAAAAAICECAEAAAAAACRECAAAAAAAICFCAAAAAAAACRECAAAAAABIvAB2MAcwDrYjZAAAAABJRU5ErkJggg==","text/plain":["<Figure size 2000x300 with 10 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1500/1500 [==============================] - 100s 59ms/step - c_loss: -1175766.1250 - c_wass_loss: -2331710.0000 - c_gp: 115594.0625 - g_loss: -12904.7812 - c_acc: 100.0000 - g_acc: 0.0000e+00\n","Epoch 2/10\n","1500/1500 [==============================] - ETA: 0s - c_loss: -1214333.7500 - c_wass_loss: -2421222.0000 - c_gp: 120688.9141 - g_loss: -2086.0449 - c_acc: 100.0000 - g_acc: 0.0000e+00\n","Saved to ./output/generated_img_001.png\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABiEAAACXCAYAAABzwvhEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFEElEQVR4nO3ZwQ3AIBDAsNL9dz6WIEJC9gT5Z83MfAAAAAAAAIf9twMAAAAAAIA3mRAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkNh3sBSrPeHzcAAAAAElFTkSuQmCC","text/plain":["<Figure size 2000x300 with 10 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1500/1500 [==============================] - 91s 61ms/step - c_loss: -1214333.7500 - c_wass_loss: -2421222.0000 - c_gp: 120688.9141 - g_loss: -2086.0449 - c_acc: 100.0000 - g_acc: 0.0000e+00\n","Epoch 3/10\n"," 165/1500 [==>...........................] - ETA: 1:27 - c_loss: -1217006.5000 - c_wass_loss: -2432042.7500 - c_gp: 121503.6641 - g_loss: -2759.1602 - c_acc: 100.0000 - g_acc: 0.0000e+00"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15000 batches). You may need to use the repeat() function when building your dataset.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Saved to ./output/generated_img_002.png\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABiEAAACXCAYAAABzwvhEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFEElEQVR4nO3ZwQ3AIBDAsNL9dz6WIEJC9gT5Z83MfAAAAAAAAIf9twMAAAAAAIA3mRAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkTAgAAAAAACBhQgAAAAAAAAkTAgAAAAAASJgQAAAAAABAwoQAAAAAAAASJgQAAAAAAJAwIQAAAAAAgIQJAQAAAAAAJEwIAAAAAAAgYUIAAAAAAAAJEwIAAAAAAEiYEAAAAAAAQMKEAAAAAAAAEiYEAAAAAACQMCEAAAAAAICECQEAAAAAACRMCAAAAAAAIGFCAAAAAAAACRMCAAAAAABImBAAAAAAAEDChAAAAAAAABImBAAAAAAAkDAhAAAAAACAhAkBAAAAAAAkNh3sBSrPeHzcAAAAAElFTkSuQmCC","text/plain":["<Figure size 2000x300 with 10 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["1500/1500 [==============================] - 12s 8ms/step - c_loss: -1217006.5000 - c_wass_loss: -2432042.7500 - c_gp: 121503.6641 - g_loss: -2759.1602 - c_acc: 100.0000 - g_acc: 0.0000e+00\n","2/2 [==============================] - 0s 6ms/step\n","2/2 [==============================] - 7s 24ms/step\n","2/2 [==============================] - 0s 155ms/step\n","2/2 [==============================] - 0s 150ms/step\n","2/2 [==============================] - 0s 100ms/step\n","Train FID: 568.079\n","Validation FID: 570.481\n","Epoch 1/10\n","1408/1500 [===========================>..] - ETA: 5s - c_loss: -1224982.8750 - c_wass_loss: -2440858.2500 - c_gp: 121587.3203 - g_loss: -2891.4526 - c_acc: 100.0000 - g_acc: 0.0000e+00"]}],"source":["loss_history = LossHistory()\n","\n","# prepare the inception v3 model\n","inception = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n","\n","for i in range(N_BLOCKS):\n","    wgangp.fit(\n","        train_data,\n","        epochs=EPOCHS,\n","        steps_per_epoch=STEPS_PER_EPOCH,\n","        callbacks=[tensorboard_callback, ImageGenerator(num_img=10, latent_dim=Z_DIM), loss_history]\n","    )\n","\n","    # calculate the generated images\n","    z_sample = np.random.normal(size=(BATCH_SIZE, Z_DIM))\n","    imgs_generated = wgangp.generator.predict(z_sample)\n","    # convert integer to floating point values\n","    example_images_train_float32 = example_images_train.astype('float32')\n","    example_images_val_float32 = example_images_val.astype('float32')\n","    imgs_generated_float32 = imgs_generated.astype('float32')\n","    # resize images\n","    example_images_train_scale = scale_images(example_images_train_float32, (299,299,3))\n","    example_images_val_scale = scale_images(example_images_val_float32, (299,299,3))\n","    imgs_generated_scale = scale_images(imgs_generated_float32, (299,299,3))\n","    # pre-process images\n","    example_images_train_preprocessed = preprocess_input(example_images_train_scale)\n","    example_images_val_preprocessed = preprocess_input(example_images_val_scale)\n","    imgs_generated_preprocessed = preprocess_input(imgs_generated_scale)\n","    # calculate fid\n","    train_fid = calculate_fid(inception, example_images_train_preprocessed, imgs_generated_preprocessed)\n","    val_fid = calculate_fid(inception, example_images_val_preprocessed, imgs_generated_preprocessed)\n","    print('Train FID: %.3f' % train_fid)\n","    print('Validation FID: %.3f' % val_fid)"]},{"cell_type":"code","execution_count":null,"id":"4db1ed24","metadata":{"id":"4db1ed24"},"outputs":[],"source":["wgangp.save_weights('/content/drive/MyDrive/MIA/DL/weights/wgan_baseline.h5')"]},{"cell_type":"code","execution_count":null,"id":"028138af-d3a5-4134-b980-d3a8a703e70f","metadata":{"id":"028138af-d3a5-4134-b980-d3a8a703e70f"},"outputs":[],"source":["# Save the final models\n","generator.save(\"/content/drive/MyDrive/MIA/DL/models/generator_baseline\")\n","critic.save(\"/content/drive/MyDrive/MIA/DL/models/critic_baseline\")"]},{"cell_type":"markdown","id":"0765b66b-d12c-42c4-90fa-2ff851a9b3f5","metadata":{"id":"0765b66b-d12c-42c4-90fa-2ff851a9b3f5"},"source":["## Generate images"]},{"cell_type":"code","execution_count":null,"id":"86576e84-afc4-443a-b68d-9a5ee13ce730","metadata":{"id":"86576e84-afc4-443a-b68d-9a5ee13ce730"},"outputs":[],"source":["z_sample = np.random.normal(size=(10, Z_DIM))\n","imgs = wgangp.generator.predict(z_sample)\n","display(imgs, cmap=None)"]},{"cell_type":"code","execution_count":null,"id":"2d405d80","metadata":{"id":"2d405d80","scrolled":false},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_losses_and_accuracy(loss_history):\n","    epochs = len(loss_history.history['c_loss'])\n","    x = range(epochs)\n","\n","    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n","\n","    axs[0, 0].plot(x, loss_history.history['c_loss'], label=\"Critic Loss\")\n","    axs[0, 0].set(xlabel=\"Epochs\", ylabel=\"Loss\")\n","    axs[0, 0].legend()\n","\n","    axs[0, 1].plot(x, loss_history.history['g_loss'], label=\"Generator Loss\")\n","    axs[0, 1].set(xlabel=\"Epochs\", ylabel=\"Loss\")\n","    axs[0, 1].legend()\n","\n","    axs[1, 0].plot(x, loss_history.history['c_acc'], label=\"Critic Accuracy\")\n","    axs[1, 0].set(xlabel=\"Epochs\", ylabel=\"Accuracy\")\n","    axs[1, 0].legend()\n","\n","    axs[1, 1].plot(x, loss_history.history['g_acc'], label=\"Generator Accuracy\")\n","    axs[1, 1].set(xlabel=\"Epochs\", ylabel=\"Accuracy\")\n","    axs[1, 1].legend()\n","\n","    plt.show()\n","\n","plot_losses_and_accuracy(loss_history)"]},{"cell_type":"code","execution_count":null,"id":"Utr9bzXCvIF9","metadata":{"id":"Utr9bzXCvIF9"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":5}
