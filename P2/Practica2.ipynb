{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Practice 2. Recurrent Neural Networks**\n",
    "\n",
    "- Alejandro Dopico Castro ([alejandro.dopico2@udc.es](mailto:alejandro.dopico2@udc.es)).\n",
    "- Ana Xiangning Pereira Ezquerro ([ana.ezquerro@udc.es](mailto:ana.ezquerro@udc.es))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 14:14:29.113623: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-25 14:14:29.145718: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-25 14:14:29.145744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-25 14:14:29.146652: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-25 14:14:29.152116: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 14:14:29.756822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.29871732e+01 5.71854780e+05 2.69656599e-01 1.88069047e+01\n",
      " 4.45318248e-01 3.89025337e+01 1.87857218e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 14:14:30.788530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1053 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2024-03-25 14:14:30.789022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21620 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from data import * \n",
    "from metric import * \n",
    "from keras.layers import * \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam \n",
    "\n",
    "# global parameters \n",
    "TEST_RATIO = 0.2\n",
    "SEQ_LENGTH = 2\n",
    "BATCH_SIZE = 30\n",
    "trainData, testData, stdSales, nFeatures = generateTrainTestData(\"Walmart.csv\", TEST_RATIO, SEQ_LENGTH, BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 14:14:40.371387: I external/local_xla/xla/service/service.cc:168] XLA service 0x5f0a1a95eb00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-25 14:14:40.371407: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-03-25 14:14:40.371412: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-03-25 14:14:40.376085: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-25 14:14:40.389748: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711372480.469465 3572375 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 10s 20ms/step - loss: 0.9972 - dmae: 283769.6250 - val_loss: 0.8726 - val_dmae: 291034.6562\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.9898 - dmae: 293302.1562 - val_loss: 0.8636 - val_dmae: 288842.5312\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 0.9698 - dmae: 276767.3750 - val_loss: 0.8361 - val_dmae: 279761.9375\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.9097 - dmae: 227166.4688 - val_loss: 0.7516 - val_dmae: 240674.7031\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.7502 - dmae: 186083.8750 - val_loss: 0.5405 - val_dmae: 162473.9219\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.4376 - dmae: 128981.8281 - val_loss: 0.2099 - val_dmae: 57027.0781\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.2487 - dmae: 114950.1719 - val_loss: 0.1060 - val_dmae: 57044.3555\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.2018 - dmae: 96754.4141 - val_loss: 0.0686 - val_dmae: 53214.9258\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1798 - dmae: 83828.9453 - val_loss: 0.0481 - val_dmae: 53941.6289\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1659 - dmae: 143983.1875 - val_loss: 0.0395 - val_dmae: 51631.2930\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1551 - dmae: 93187.6562 - val_loss: 0.0344 - val_dmae: 50063.6055\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1472 - dmae: 80163.5703 - val_loss: 0.0318 - val_dmae: 48216.3164\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1405 - dmae: 98087.1562 - val_loss: 0.0311 - val_dmae: 47299.5117\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1359 - dmae: 77719.3906 - val_loss: 0.0305 - val_dmae: 43312.9531\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1326 - dmae: 141019.9844 - val_loss: 0.0302 - val_dmae: 42735.5195\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1278 - dmae: 125233.8672 - val_loss: 0.0305 - val_dmae: 42934.1133\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1271 - dmae: 86666.1719 - val_loss: 0.0306 - val_dmae: 41617.7344\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1218 - dmae: 102622.0078 - val_loss: 0.0298 - val_dmae: 40342.7539\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1209 - dmae: 131467.7656 - val_loss: 0.0293 - val_dmae: 38629.6680\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1183 - dmae: 52491.7852 - val_loss: 0.0298 - val_dmae: 38731.1406\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1172 - dmae: 46328.2695 - val_loss: 0.0291 - val_dmae: 37474.7773\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1144 - dmae: 106231.6641 - val_loss: 0.0288 - val_dmae: 36255.6055\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1117 - dmae: 93379.7031 - val_loss: 0.0285 - val_dmae: 34278.3086\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1109 - dmae: 80441.7266 - val_loss: 0.0282 - val_dmae: 34585.9492\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1093 - dmae: 58304.8867 - val_loss: 0.0281 - val_dmae: 33503.2891\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1088 - dmae: 108482.8672 - val_loss: 0.0280 - val_dmae: 33478.9688\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1053 - dmae: 122442.5938 - val_loss: 0.0272 - val_dmae: 33120.7617\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1033 - dmae: 137125.2188 - val_loss: 0.0276 - val_dmae: 34946.6836\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1014 - dmae: 91446.7969 - val_loss: 0.0274 - val_dmae: 32342.1621\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1026 - dmae: 128619.6016 - val_loss: 0.0272 - val_dmae: 31831.6191\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.1006 - dmae: 105474.7734 - val_loss: 0.0264 - val_dmae: 32851.8047\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0998 - dmae: 122117.2109 - val_loss: 0.0261 - val_dmae: 32352.4746\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0986 - dmae: 72955.9375 - val_loss: 0.0262 - val_dmae: 32110.0938\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0973 - dmae: 95207.0234 - val_loss: 0.0260 - val_dmae: 32025.2090\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0965 - dmae: 143192.6250 - val_loss: 0.0254 - val_dmae: 31654.1016\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0957 - dmae: 121787.7891 - val_loss: 0.0254 - val_dmae: 31035.0938\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0936 - dmae: 131560.4531 - val_loss: 0.0254 - val_dmae: 32153.4082\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0935 - dmae: 119923.1328 - val_loss: 0.0250 - val_dmae: 31612.6094\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0921 - dmae: 58408.5781 - val_loss: 0.0248 - val_dmae: 31680.5254\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0925 - dmae: 143899.4688 - val_loss: 0.0247 - val_dmae: 31545.4609\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0927 - dmae: 77234.9609 - val_loss: 0.0248 - val_dmae: 31666.5000\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0912 - dmae: 94319.5312 - val_loss: 0.0244 - val_dmae: 32143.9922\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0892 - dmae: 140562.5469 - val_loss: 0.0244 - val_dmae: 31843.5625\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0881 - dmae: 111021.8047 - val_loss: 0.0244 - val_dmae: 32453.5059\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0878 - dmae: 77710.2734 - val_loss: 0.0240 - val_dmae: 32028.9160\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0879 - dmae: 62849.9688 - val_loss: 0.0241 - val_dmae: 32319.8594\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0873 - dmae: 123281.0156 - val_loss: 0.0241 - val_dmae: 32764.7246\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0856 - dmae: 66769.8281 - val_loss: 0.0233 - val_dmae: 31277.7480\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0839 - dmae: 86458.1562 - val_loss: 0.0233 - val_dmae: 31346.6562\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0853 - dmae: 120218.1719 - val_loss: 0.0235 - val_dmae: 31264.0078\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0839 - dmae: 114289.0547 - val_loss: 0.0230 - val_dmae: 31394.3652\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0835 - dmae: 52788.5547 - val_loss: 0.0228 - val_dmae: 31574.0391\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0835 - dmae: 67545.4922 - val_loss: 0.0233 - val_dmae: 31703.5293\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0812 - dmae: 65374.9336 - val_loss: 0.0230 - val_dmae: 31493.0020\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0821 - dmae: 130288.3438 - val_loss: 0.0229 - val_dmae: 31251.4121\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0799 - dmae: 91073.6484 - val_loss: 0.0224 - val_dmae: 31447.3750\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0806 - dmae: 46006.4258 - val_loss: 0.0229 - val_dmae: 30900.4160\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0797 - dmae: 107712.0156 - val_loss: 0.0226 - val_dmae: 31873.7910\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 3s 16ms/step - loss: 0.0792 - dmae: 67078.3672 - val_loss: 0.0226 - val_dmae: 31040.9590\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0796 - dmae: 108525.4297 - val_loss: 0.0227 - val_dmae: 30847.1484\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0788 - dmae: 105486.4766 - val_loss: 0.0223 - val_dmae: 31291.2559\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0781 - dmae: 83573.2109 - val_loss: 0.0226 - val_dmae: 30771.0957\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0773 - dmae: 75267.9062 - val_loss: 0.0223 - val_dmae: 31263.0527\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0785 - dmae: 118121.8516 - val_loss: 0.0225 - val_dmae: 30569.9844\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0774 - dmae: 100839.7578 - val_loss: 0.0221 - val_dmae: 30987.6973\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0762 - dmae: 110683.4609 - val_loss: 0.0228 - val_dmae: 31533.2422\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0760 - dmae: 69590.3438 - val_loss: 0.0223 - val_dmae: 31075.4238\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0765 - dmae: 170294.7344 - val_loss: 0.0217 - val_dmae: 31335.8906\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0750 - dmae: 116393.6016 - val_loss: 0.0225 - val_dmae: 30449.4199\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0755 - dmae: 110942.6328 - val_loss: 0.0220 - val_dmae: 30646.4824\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0742 - dmae: 56363.6719 - val_loss: 0.0219 - val_dmae: 30726.8809\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0738 - dmae: 90829.2109 - val_loss: 0.0221 - val_dmae: 30371.4121\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0745 - dmae: 100005.5078 - val_loss: 0.0219 - val_dmae: 30219.6875\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0733 - dmae: 79945.1016 - val_loss: 0.0224 - val_dmae: 30206.0859\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0734 - dmae: 58883.3945 - val_loss: 0.0219 - val_dmae: 30494.3105\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0724 - dmae: 85507.0078 - val_loss: 0.0224 - val_dmae: 30938.2129\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0711 - dmae: 69854.5781 - val_loss: 0.0221 - val_dmae: 31806.3223\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0736 - dmae: 78007.4219 - val_loss: 0.0221 - val_dmae: 30436.6016\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0718 - dmae: 105754.8672 - val_loss: 0.0220 - val_dmae: 32333.3027\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0713 - dmae: 44385.9492 - val_loss: 0.0227 - val_dmae: 30382.1504\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0714 - dmae: 101415.8125 - val_loss: 0.0230 - val_dmae: 30219.0391\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0711 - dmae: 93987.7109 - val_loss: 0.0222 - val_dmae: 31355.4844\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0714 - dmae: 55019.6758 - val_loss: 0.0225 - val_dmae: 31004.7129\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0698 - dmae: 59769.4727 - val_loss: 0.0217 - val_dmae: 31518.4551\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0710 - dmae: 79837.0078 - val_loss: 0.0224 - val_dmae: 31152.2793\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0687 - dmae: 93071.2266 - val_loss: 0.0224 - val_dmae: 32739.4707\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0698 - dmae: 68950.9297 - val_loss: 0.0223 - val_dmae: 31242.2480\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0695 - dmae: 113389.4062 - val_loss: 0.0225 - val_dmae: 30152.5020\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0680 - dmae: 86409.0312 - val_loss: 0.0225 - val_dmae: 30565.2578\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0678 - dmae: 73725.9375 - val_loss: 0.0222 - val_dmae: 30480.9473\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0667 - dmae: 112344.4219 - val_loss: 0.0227 - val_dmae: 32367.9941\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0670 - dmae: 62261.2305 - val_loss: 0.0227 - val_dmae: 30794.1387\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0670 - dmae: 90205.0391 - val_loss: 0.0225 - val_dmae: 34344.0938\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0663 - dmae: 63907.1133 - val_loss: 0.0229 - val_dmae: 33421.0938\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0673 - dmae: 62960.1055 - val_loss: 0.0226 - val_dmae: 31669.2734\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0661 - dmae: 74870.6953 - val_loss: 0.0229 - val_dmae: 32867.1172\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0654 - dmae: 65215.0117 - val_loss: 0.0231 - val_dmae: 32026.7246\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0659 - dmae: 61771.1172 - val_loss: 0.0234 - val_dmae: 32394.0723\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0647 - dmae: 120027.2109 - val_loss: 0.0235 - val_dmae: 33668.8086\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 0.0650 - dmae: 59562.8477 - val_loss: 0.0234 - val_dmae: 33112.9648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x719d9f91b0d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(BATCH_SIZE, nFeatures)),\n",
    "    Bidirectional(LSTM(units=20, activation='relu', return_sequences=True)),\n",
    "    Bidirectional(LSTM(units=20, activation='relu', return_sequences=True)),\n",
    "    Dropout(0.1),\n",
    "    Bidirectional(LSTM(units=20, activation='relu')),\n",
    "    Dense(10, activation='relu'), Dense(1)\n",
    "])\n",
    "optimizer = Adam(1e-4)\n",
    "\n",
    "class DenormalizedMAE(Metric):\n",
    "    def __init__(self, std: float, name='dmae', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.std = std \n",
    "        self.value = self.add_weight(shape=(), initializer='zeros', name='value')\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.multiply(y_true, self.std)\n",
    "        y_pred = tf.multiply(y_pred, self.std)\n",
    "        result = tf.reduce_mean(tf.abs(tf.subtract(y_true, y_pred)))\n",
    "        self.value.assign(result)\n",
    "        \n",
    "    def result(self):\n",
    "        return self.value\n",
    "\n",
    "model.compile(optimizer, 'mse', metrics=[DenormalizedMAE(stdSales)])\n",
    "model.fit(trainData, epochs=100, validation_data=testData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
