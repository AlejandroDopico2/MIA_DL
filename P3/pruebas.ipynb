{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle \n",
    "from typing import Dict, List, Tuple, Callable\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from data import CelebADataset\n",
    "from tensorflow.keras.callbacks import (\n",
    "    Callback,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TensorBoard,\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    "    Reshape,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Lambda,\n",
    "    Concatenate\n",
    ")\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Optimizer\n",
    "from PIL import Image\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from skimage.transform import resize\n",
    "from numpy import cov, iscomplexobj, trace\n",
    "from scipy.linalg import sqrtm\n",
    "from keras import backend as K\n",
    "from utils import SaveImagesCallback, FID\n",
    "from keras.activations import tanh\n",
    "\n",
    "hidden_size = 200\n",
    "img_size = (128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 19:58:25.552387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22453 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n",
      "2024-05-23 19:58:25.552909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 5858 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "critic_input = Input(shape=img_size)\n",
    "x = Conv2D(32, kernel_size=4, strides=2, padding=\"same\")(critic_input)\n",
    "x = LeakyReLU(0.2)(x)\n",
    "x = Conv2D(32, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x = LeakyReLU(0.2)(x)\n",
    "x = Conv2D(32, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv2D(32, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x = LeakyReLU(0.2)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv2D(32, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x = LeakyReLU(0.2)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv2D(1, kernel_size=4, strides=1, padding=\"valid\")(x)\n",
    "critic_output = Flatten()(x)\n",
    "\n",
    "critic = Model(critic_input, critic_output, name=\"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " encoder-input (InputLayer)  [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1 (Sequential)          (None, 64, 64, 64)           3328      ['encoder-input[0][0]']       \n",
      "                                                                                                  \n",
      " conv2 (Sequential)          (None, 32, 32, 128)          131584    ['conv1[0][0]']               \n",
      "                                                                                                  \n",
      " conv3 (Sequential)          (None, 16, 16, 256)          525312    ['conv2[0][0]']               \n",
      "                                                                                                  \n",
      " conv4 (Sequential)          (None, 8, 8, 512)            2099200   ['conv3[0][0]']               \n",
      "                                                                                                  \n",
      " conv5 (Sequential)          (None, 4, 4, 512)            4196352   ['conv4[0][0]']               \n",
      "                                                                                                  \n",
      " latent (Sequential)         (None, 2048)                 4196352   ['conv5[0][0]']               \n",
      "                                                                                                  \n",
      " mean (Dense)                (None, 200)                  409800    ['latent[0][0]']              \n",
      "                                                                                                  \n",
      " log-var (Dense)             (None, 200)                  409800    ['latent[0][0]']              \n",
      "                                                                                                  \n",
      " encoder-output (Lambda)     (None, 200)                  0         ['mean[0][0]',                \n",
      "                                                                     'log-var[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11971728 (45.67 MB)\n",
      "Trainable params: 11967760 (45.65 MB)\n",
      "Non-trainable params: 3968 (15.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def sampling(args):\n",
    "        mean_mu, log_var = args\n",
    "        epsilon = K.random_normal(shape=K.shape(mean_mu), mean=0.0, stddev=1.0)\n",
    "        return mean_mu + K.exp(log_var / 2) * epsilon\n",
    "    \n",
    "encoder_input = Input(shape=img_size, name='encoder-input')\n",
    "conv1 = Sequential([\n",
    "    Conv2D(64, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "    BatchNormalization(momentum=0.9), LeakyReLU(0.2)\n",
    "], name='conv1')(encoder_input)\n",
    "conv2 = Sequential([\n",
    "    Conv2D(128, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "    BatchNormalization(momentum=0.9), LeakyReLU(0.2)\n",
    "], name='conv2')(conv1)\n",
    "conv3 = Sequential([\n",
    "    Conv2D(256, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "    BatchNormalization(momentum=0.9), LeakyReLU(0.2)\n",
    "], name='conv3')(conv2)\n",
    "conv4 = Sequential([\n",
    "    Conv2D(512, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "    BatchNormalization(momentum=0.9), LeakyReLU(0.2)\n",
    "], name='conv4')(conv3)\n",
    "conv5 = Sequential([\n",
    "    Conv2D(512, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "    BatchNormalization(momentum=0.9), LeakyReLU(0.2)\n",
    "], name='conv5')(conv4)\n",
    "latent = Sequential([\n",
    "    Conv2D(512, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "    BatchNormalization(momentum=0.9), LeakyReLU(0.2),\n",
    "    Flatten()\n",
    "], name='latent')(conv5)\n",
    "\n",
    "mean = Dense(hidden_size, name='mean')(latent)\n",
    "logvar = Dense(hidden_size, name='log-var')(latent)\n",
    "encoder_output = Lambda(sampling, name=\"encoder-output\")([mean, logvar])\n",
    "encoder = Model(encoder_input, encoder_output, name='encoder')\n",
    "\n",
    "print(encoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='encoder-input'), name='encoder-input', description=\"created by layer 'encoder-input'\") at layer \"conv1\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 37\u001b[0m\n\u001b[1;32m     11\u001b[0m deconv5 \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m     12\u001b[0m     Concatenate(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     13\u001b[0m     Conv2DTranspose(\u001b[38;5;241m512\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     14\u001b[0m     BatchNormalization(momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m), LeakyReLU(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[1;32m     15\u001b[0m ], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeconv5\u001b[39m\u001b[38;5;124m'\u001b[39m)([deconv6, conv5])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# deconv4 = Sequential([\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     Conv2DTranspose(512, kernel_size=4, strides=2, padding='same', use_bias=False),\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     BatchNormalization(momentum=0.9), LeakyReLU(0.2),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#     Activation(tanh)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# ], name='output')(deconv1)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m decoder \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeconv5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdecoder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m decoder\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/Documents/dl-labs/P3/.venv/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/dl-labs/P3/.venv/lib/python3.10/site-packages/keras/src/engine/functional.py:166\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    158\u001b[0m         [\n\u001b[1;32m    159\u001b[0m             functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    161\u001b[0m         ]\n\u001b[1;32m    162\u001b[0m     ):\n\u001b[1;32m    163\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    164\u001b[0m             inputs, outputs\n\u001b[1;32m    165\u001b[0m         )\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dl-labs/P3/.venv/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/dl-labs/P3/.venv/lib/python3.10/site-packages/keras/src/engine/functional.py:265\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_coordinates\u001b[38;5;241m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_map_graph_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/Documents/dl-labs/P3/.venv/lib/python3.10/site-packages/keras/src/engine/functional.py:1145\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39mkeras_inputs):\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(x) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m computable_tensors:\n\u001b[0;32m-> 1145\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1146\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph disconnected: cannot obtain value for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1147\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1148\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following previous layers were accessed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1149\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout issue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayers_with_complete_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1150\u001b[0m         )\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39moutputs):\n\u001b[1;32m   1152\u001b[0m     computable_tensors\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(x))\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='encoder-input'), name='encoder-input', description=\"created by layer 'encoder-input'\") at layer \"conv1\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "decoder_input = Input(shape=(hidden_size, ), name='decoder-input')\n",
    "deconv7 = Sequential([\n",
    "    Reshape(target_shape=(1, 1, hidden_size)),\n",
    "    Conv2DTranspose(512, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "    BatchNormalization(momentum=0.9), LeakyReLU(0.2),\n",
    "], name='deconv7')(decoder_input)\n",
    "deconv6 = Sequential([\n",
    "    Conv2DTranspose(512, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "    BatchNormalization(momentum=0.9), LeakyReLU(0.2),\n",
    "], name='deconv6')(deconv7)\n",
    "deconv5 = Sequential([\n",
    "    Concatenate(-1),\n",
    "    Conv2DTranspose(512, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "    BatchNormalization(momentum=0.9), LeakyReLU(0.2),\n",
    "], name='deconv5')([deconv6, conv5])\n",
    "# deconv4 = Sequential([\n",
    "#     Conv2DTranspose(512, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "#     BatchNormalization(momentum=0.9), LeakyReLU(0.2),\n",
    "# ], name='deconv4')(deconv5)\n",
    "# deconv3 = Sequential([\n",
    "#     Conv2DTranspose(256, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "#     BatchNormalization(momentum=0.9), LeakyReLU(0.2),\n",
    "# ], name='deconv3')(deconv4)\n",
    "# deconv2 = Sequential([\n",
    "#     Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "#     BatchNormalization(momentum=0.9), LeakyReLU(0.2),\n",
    "# ], name='deconv2')(deconv3)\n",
    "# deconv1 = Sequential([\n",
    "#     Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
    "#     BatchNormalization(momentum=0.9), LeakyReLU(0.2),\n",
    "# ], name='deconv1')(deconv2)\n",
    "# decoder_output = Sequential([\n",
    "#     Conv2DTranspose(3, kernel_size=1, use_bias=False),\n",
    "#     Activation(tanh)\n",
    "# ], name='output')(deconv1)\n",
    "\n",
    "decoder = Model(decoder_input, deconv5, name='decoder')\n",
    "decoder.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
